{"cells":[{"cell_type":"code","source":["!pip install faiss-cpu --no-cache"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a424b415-b8ef-47b3-84ee-7c40332e01ef","outputId":"5a16988b-7a49-4ccb-efc3-0e6324020197","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a1c1cdf-64b0-4890-9e0e-cb11d412961b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Requirement already satisfied: faiss-cpu in /databricks/python3/lib/python3.8/site-packages (1.7.2)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Requirement already satisfied: faiss-cpu in /databricks/python3/lib/python3.8/site-packages (1.7.2)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import pickle\nimport faiss\nimport numpy as np"],"metadata":{"id":"837dcaa9-cc0b-4345-bbee-3a09683decf9","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"11ba8c52-8bca-4608-8788-56179142047f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# **Welcome to week 3 project!**\n\nCongratulations on making it to week 3! üëè In the first week of this course, we covered the basics of how to design personalized recommendation systems. We then provided some system design examples for large scale recommenders from corporations like Spotify and YouTube, as well as techniques for candidate generation, specifically the two-tower model being used at Twitter and Pinterest.\n\nLast week, we covered details of ML approaches for recommendations: including multi-task recommenders and contextual bandits.\n\nIn week 3, we covered various techniques for learning user representations.\n\nIn this week's project, we will touch upon two key aspects related to representations:\n1. How do we query large amount of vectors in efficient time.\n2. How can we infer various user representations and see what their impact is on downstream task.\n\nLets begin with Part A, which tells us how we could handle a large number of candidate items or user representations in an efficient manner."],"metadata":{"id":"41f1f7cb-9441-4fe1-962e-9e4cb3e3c192","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f9001472-2514-4dbd-a80f-3f90088f5b48"}}},{"cell_type":"markdown","source":["# Part A: Approximate nearest neighbor search\n\nOften we are interested in finding nearest neighbors in a large space of vectors. To store embeddings for 400 million users and over 100 million items and querying them in real time is a challenging task. This is where approximate nearest neighbor approaches step in to help. Annoy, Faiss, ScaNN are typical libraries that are used for efficient vector similarity search at scale. They implement algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM.\n\nIn the first part of this week's project, we will simulate embeddings of 1 million items and try to find k-nearest neighbours for an item of interest. We will implement a vanilla search function to fetch the top-k nearest neighbors and estimate the time it takes for us to do so. We will then compare this with FAISS -- Facebook's nearest neighbour search library, and compare the time it takes for us to get nearest neighbours from FAISS versus our own implementation."],"metadata":{"id":"d0e01328-6834-4b11-85c1-03867e1d4860","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c7aed16-0a29-425f-8f91-148fe7cd84bc"}}},{"cell_type":"markdown","source":["Lets first generate a simulated dataset of embeddings of 1 million items."],"metadata":{"id":"3fa2b438-be53-4f39-b990-859046a4a560","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb5edb9c-ce40-4762-95ca-39646fd74181"}}},{"cell_type":"code","source":["d = 64                           # dimension\nnb = 1000000                     # database size\nnq = 10000                       # nb of queries\nnp.random.seed(1234)             # make reproducible\nxb = np.random.random((nb, d)).astype('float32')\nxq = np.random.random((nq, d)).astype('float32')"],"metadata":{"id":"8c36fc8b-a032-4b48-bbeb-3bff46624615","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dcfc4797-403e-4a0f-962c-86354cb74310"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now that we have these items, lets take up the goal of finding the top-5 items closest to this specific item. Your goal is to implement your function to estimate the top-5 items and print the average distance of these top 5 items to the query item."],"metadata":{"id":"142c00a5-f36b-4a5f-9e27-4a3e38b467d7","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64ad553b-46b2-478d-8047-14f1147d9cce"}}},{"cell_type":"code","source":["k=4\nquery_vector = xb[2:3]"],"metadata":{"id":"b2dd70b9-8d2c-4134-b866-ab09af43a47d","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ab9318c-b628-4d63-a2cf-fcbd8e771c3c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def find_top_k_nn(query_vector,k):\n    \"\"\"\n    in this function, implement your definition of top-k nearest neighbours, and return the distances\n    and indices of the these top-k items.\n    \"\"\"\n    distances = np.sqrt(np.sum(np.square(xb-query_vector), axis=1))\n    topKArgs = distances.argsort()[-1*k:][::-1]\n    return distances[topKArgs], topKArgs"],"metadata":{"id":"84a94ee2-3131-44c5-ba95-ec67aa675048","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0ab5d313-0764-43a9-bc22-453d324bdea2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["With your top-k NN function implemented, call this function to get the top-k nearest neighbor items for the query_vector and print the average distance. Also, print the time it takes to run this function:"],"metadata":{"id":"b8a895ce-4f0b-41a5-8243-90f18bff8d7b","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"481e4b36-76f6-4f14-8713-71aa7d3498e9"}}},{"cell_type":"code","source":["%%time\nD, I = find_top_k_nn(query_vector, k)\nprint(\"distances from the k nearest neighbor fetched:\",D)\nprint(\"indices from the k nearest neighbor fetched:\",I)\nprint(\"average distance of the k- nearest neighbors fetched: \",D.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"0df9e9f8-a854-4896-9ebd-fd74bad21690","outputId":"42ca8e55-76ca-4dae-f960-6b0f5cb37c23","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c22023a-ca2e-4357-b0e2-fcaed8011fc2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">distances from the k nearest neighbor fetched: [4.2939873 4.2388873 4.2324553 4.2306   ]\nindices from the k nearest neighbor fetched: [246664   9185 492301 785469]\naverage distance of the k- nearest neighbors fetched:  4.2489824\nCPU times: user 273 ms, sys: 55.9 ms, total: 329 ms\nWall time: 328 ms\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">distances from the k nearest neighbor fetched: [4.2939873 4.2388873 4.2324553 4.2306   ]\nindices from the k nearest neighbor fetched: [246664   9185 492301 785469]\naverage distance of the k- nearest neighbors fetched:  4.2489824\nCPU times: user 273 ms, sys: 55.9 ms, total: 329 ms\nWall time: 328 ms\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now lets switch to using Faiss https://github.com/facebookresearch/faiss\n\nFaiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM."],"metadata":{"id":"bd4452f5-ce17-43df-95f2-e9b58e8cad5e","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15001772-6b80-4764-92f9-dcd3490a5328"}}},{"cell_type":"markdown","source":["### Similarity search in Faiss\n\nGiven a set of vectors x_i in dimension d, Faiss builds a data structure in RAM. After the structure is constructed, when given a new vector x in dimension d it performs efficiently the operation:\n\n$i = argmin_i ||x - x_i||$\n\nwhere ||.|| is the Euclidean distance (L2).\n\nIn Faiss terms, the data structure is an index, an object that has an add method to add x_i vectors. Note that the x_i's are assumed to be fixed. Computing the argmin is the search operation on the index.\n\n### Indexes used by Faiss\n\n1. The inverted file from ‚ÄúVideo google: A text retrieval approach to object matching in videos.‚Äù, Sivic & Zisserman, ICCV 2003. This is the key to non-exhaustive search in large datasets. Otherwise all searches would need to scan all elements in the index, which is prohibitive even if the operation to apply for each element is fast\n\n\n2. The product quantization (PQ) method from ‚ÄúProduct quantization for nearest neighbor search‚Äù, J√©gou & al., PAMI 2011. This can be seen as a lossy compression technique for high-dimensional vectors, that allows relatively accurate reconstructions and distance computations in the compressed domain.\n\n\n3. The three-level quantization (IVFADC-R aka IndexIVFPQR) method from \"Searching in one billion vectors: re-rank with source coding\", Tavenard & al., ICASSP'11."],"metadata":{"id":"b6427be9-53b2-446c-851b-b2f6b7db9fa6","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec42c0c1-46b0-465c-b47d-8b2f644b35cf"}}},{"cell_type":"markdown","source":["We will implement these three indexes from faiss and use each of these three to search the index, and get the top-k nearest neighbour vectors, and estimate the average distance.\n\nLets first construct the three indexes: index1, index2, index3 based on Flat index, Inverted index and product quantization techniques:"],"metadata":{"id":"3e63810d-fd22-49ca-b4bd-423ebf348c5f","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2630b0d2-3c06-4578-bbcd-2ee65f50e2b4"}}},{"cell_type":"code","source":["%%time\nindex1 = faiss.IndexFlatL2(d)   # build the index\nindex1.add(xb)                  # add vectors to the index\nprint(\"total number of vectors indexed = \",index1.ntotal)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"76487ec4-a020-4ccd-aa33-f6ef25869048","outputId":"8f8f947f-c32e-4a5b-92db-0fbaecbe542d","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fda5f3a0-b0a3-4d18-9fc9-ceb6757e7e7d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">total number of vectors indexed =  1000000\nCPU times: user 43.6 ms, sys: 59.9 ms, total: 103 ms\nWall time: 103 ms\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">total number of vectors indexed =  1000000\nCPU times: user 43.6 ms, sys: 59.9 ms, total: 103 ms\nWall time: 103 ms\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%%time\nnlist = 100\nquantizer = faiss.IndexFlatL2(d)  # the other index\nindex2 = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)\nindex2.train(xb)\nindex2.add(xb)\nprint(\"total number of vectors indexed = \",index2.ntotal)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"55447035-57e2-4938-837b-9bf20bf66ff6","outputId":"269f5ed4-2448-4bbc-af47-8161845d0b5d","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"450c5bf8-f697-4505-95bf-f9ff8532cf90"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">total number of vectors indexed =  1000000\nCPU times: user 8.88 s, sys: 283 ms, total: 9.16 s\nWall time: 1.26 s\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">total number of vectors indexed =  1000000\nCPU times: user 8.88 s, sys: 283 ms, total: 9.16 s\nWall time: 1.26 s\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%%time\nnlist = 100\nm = 8\nk = 4\nquantizer = faiss.IndexFlatL2(d)  # this remains the same\nindex3 = faiss.IndexIVFPQ(quantizer, d, nlist, m, 8)\n                                  # 8 specifies that each sub-vector is encoded as 8 bits\nindex3.train(xb)\nindex3.add(xb)\nprint(\"total number of vectors indexed = \",index3.ntotal)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f04ebe3c-705d-49b2-aa7b-3602c111c754","outputId":"ee5d4bbf-6a57-4f55-b855-3936da5a099f","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0ab7e3d7-af4f-47eb-ae97-d67d55dbdd85"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now that we have these three indexes, let us query these to fetch the top-k nearest neghbour for our query_vector and compute the average distance we obtain for each.\n\nWe will also time these commands, to find out the trade-off between accuracy and latency."],"metadata":{"id":"047a6682-f771-4672-8998-307f4cfad5f5","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7b303cb-c2cd-4211-a36e-80d7c40b1acd"}}},{"cell_type":"code","source":["%%time\nD, I = index1.search(query_vector, k)\nprint(\"distances from the k nearest neighbor fetched:\", D)\nprint(\"indices from the k nearest neighbor fetched:\", I)\nprint(\"average distance of the k- nearest neighbors fetched: \", D.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2e54dc7d-5d15-47b2-85e4-c583f92d52a8","outputId":"5052a190-c81e-43d9-854c-84cdb824961d","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c2f5333-201d-42e7-bd04-3785c13e0da0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">distances from the k nearest neighbor fetched: [[0.        4.2204943 4.3854527 4.6933837]]\nindices from the k nearest neighbor fetched: [[     2 379284 539651 400245]]\naverage distance of the k- nearest neighbors fetched:  3.324833\nCPU times: user 53 ms, sys: 0 ns, total: 53 ms\nWall time: 53 ms\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">distances from the k nearest neighbor fetched: [[0.        4.2204943 4.3854527 4.6933837]]\nindices from the k nearest neighbor fetched: [[     2 379284 539651 400245]]\naverage distance of the k- nearest neighbors fetched:  3.324833\nCPU times: user 53 ms, sys: 0 ns, total: 53 ms\nWall time: 53 ms\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%%time\nD, I = index2.search(query_vector, k)\nprint(\"distances from the k nearest neighbor fetched:\", D)\nprint(\"indices from the k nearest neighbor fetched:\", I)\nprint(\"average distance of the k- nearest neighbors fetched: \", D.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"be8f1b17-6108-41fd-814c-caa996fb731d","outputId":"2e0ecbda-dd59-4e3e-db7c-6ae4a465ae74","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"605ab33b-a3ef-41db-934a-88466ecb63f1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">distances from the k nearest neighbor fetched: [[0.        5.0635023 5.4133463 5.642405 ]]\nindices from the k nearest neighbor fetched: [[     2 859123 177280  74082]]\naverage distance of the k- nearest neighbors fetched:  4.0298133\nCPU times: user 1.24 ms, sys: 16 ¬µs, total: 1.26 ms\nWall time: 1.27 ms\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">distances from the k nearest neighbor fetched: [[0.        5.0635023 5.4133463 5.642405 ]]\nindices from the k nearest neighbor fetched: [[     2 859123 177280  74082]]\naverage distance of the k- nearest neighbors fetched:  4.0298133\nCPU times: user 1.24 ms, sys: 16 ¬µs, total: 1.26 ms\nWall time: 1.27 ms\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%%time\nD, I = index3.search(query_vector, k)\nprint(\"distances from the k nearest neighbor fetched:\", D)\nprint(\"indices from the k nearest neighbor fetched:\", I)\nprint(\"average distance of the k- nearest neighbors fetched: \", D.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2b230291-517c-49c5-a634-f9d4d331e241","outputId":"e0b43671-bd84-412a-b9ff-49148d1805d8","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a29889bb-f898-4427-b48f-f4d38e76980d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">distances from the k nearest neighbor fetched: [[1.1111705 5.027693  5.1296997 5.1854224]]\nindices from the k nearest neighbor fetched: [[     2 351653 703885 841943]]\naverage distance of the k- nearest neighbors fetched:  4.1134963\nCPU times: user 884 ¬µs, sys: 0 ns, total: 884 ¬µs\nWall time: 889 ¬µs\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">distances from the k nearest neighbor fetched: [[1.1111705 5.027693  5.1296997 5.1854224]]\nindices from the k nearest neighbor fetched: [[     2 351653 703885 841943]]\naverage distance of the k- nearest neighbors fetched:  4.1134963\nCPU times: user 884 ¬µs, sys: 0 ns, total: 884 ¬µs\nWall time: 889 ¬µs\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Running all these, we observe that the product quantization based index is an order of magnitude faster than the inverted index. In terms of accuracy, if we assume that the lower the distance the more accurate the result, FlatIndex gives us the least distance."],"metadata":{"id":"c2c902e3-c9bf-408e-9052-11af5a3b069f","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ddb2466d-fefe-40ab-b0c8-af8bef429c7a"}}},{"cell_type":"markdown","source":["### Goal 1 for this week: Implement your k-NN function and time it\n\nThe main goal for this part of the project is to implement your vanilla nearest neighbor function and fetch the closest k nearest neighbours to the query vector. Important to note that your implementation will give an exact result, i.e., your implementation will find the exact closest k vectors that will give the minimum distance to the query_vector.\n\nPlease compile the results in a table, and compare the average distance obtained and the time it took to query the 1 million vectors. A nice 2D plot would also give you a good idea of the speed-accuracy trade-off involved."],"metadata":{"id":"044a818f-19ab-4c26-8532-922c9aa1d673","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae2b7c31-1750-4316-9e4a-9b62a2c26bbe"}}},{"cell_type":"code","source":["import time\n\nmethod_times = []\n\nstart = time.time()\nD, I = index1.search(query_vector, k)\nend = time.time()\nmethod_times.append((\"index1\", end-start))\n\nstart = time.time()\nD, I = index2.search(query_vector, k)\nend = time.time()\nmethod_times.append((\"index2\", end-start))\n\nstart = time.time()\nD, I = index3.search(query_vector, k)\nend = time.time()\nmethod_times.append((\"index3\", end-start))\n\nstart = time.time()\nD, I = find_top_k_nn(query_vector, k)\nend = time.time()\nmethod_times.append((\"find_top_k_nn\", end-start))\n\nimport pandas as pd\npd.DataFrame(method_times, columns=[\"method\", \"time\"]).set_index(\"method\")[\"time\"].plot(kind=\"bar\")"],"metadata":{"id":"2e69dd09-6a21-49a8-8ca8-4d5164a7e674","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e35a9d9-137a-4e96-9a38-2c2b32a7c895"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[13]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"data:image/png;base64,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","removedWidgets":[],"addedWidgets":{},"metadata":{"imageDimensions":{"width":378,"height":321}},"type":"image","arguments":{}},"image/png":{"width":378,"height":321}},"output_type":"display_data","data":{"image/png":"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"}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;AxesSubplot:xlabel=&#39;method&#39;&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;AxesSubplot:xlabel=&#39;method&#39;&gt;</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Part B: User representations"],"metadata":{"id":"e127987e-44f9-43b3-9219-1036edd0d14c","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fb795961-cd1a-423f-bac4-46b7835a7c1b"}}},{"cell_type":"markdown","source":["In the second part of this week's project, we wish to understand few ways of estimating user representations, and how it impacts the performance of downstream tasks.\n\nTo this end, we will work on top of our H&M dataset, and develop a few different ways of representing users.\n\nThe broader framework here will be -- we fix the article representations, and fix the downstream task, and then vary the user representations and see how the performance of the downstream task changes based on different user representation techniques."],"metadata":{"id":"13c18e33-3a62-4afe-95af-9d33ef87917c","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6fc531e2-2381-4d0a-ab40-aab6a11edc80"}}},{"cell_type":"code","source":["!pip install lightgbm"],"metadata":{"id":"dd824205-1569-4b54-8c48-fda93a59053d","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ce9a4361-c90e-461a-bf3c-d87a0c80669a"},"colab":{"base_uri":"https://localhost:8080/"},"scrolled":true,"outputId":"a821f59c-db3e-4f43-f1bf-a5d27e4c203c"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Requirement already satisfied: lightgbm in /databricks/python3/lib/python3.8/site-packages (3.3.2)\r\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (from lightgbm) (1.20.1)\r\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (from lightgbm) (1.6.2)\r\nRequirement already satisfied: scikit-learn!=0.22.0 in /databricks/python3/lib/python3.8/site-packages (from lightgbm) (0.24.1)\r\nRequirement already satisfied: wheel in /databricks/python3/lib/python3.8/site-packages (from lightgbm) (0.36.2)\r\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn!=0.22.0-&gt;lightgbm) (1.0.1)\r\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn!=0.22.0-&gt;lightgbm) (2.1.0)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Requirement already satisfied: lightgbm in /databricks/python3/lib/python3.8/site-packages (3.3.2)\r\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (from lightgbm) (1.20.1)\r\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (from lightgbm) (1.6.2)\r\nRequirement already satisfied: scikit-learn!=0.22.0 in /databricks/python3/lib/python3.8/site-packages (from lightgbm) (0.24.1)\r\nRequirement already satisfied: wheel in /databricks/python3/lib/python3.8/site-packages (from lightgbm) (0.36.2)\r\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn!=0.22.0-&gt;lightgbm) (1.0.1)\r\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn!=0.22.0-&gt;lightgbm) (2.1.0)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nimport gc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GroupShuffleSplit\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nimport lightgbm as lgb\nimport datetime\nimport itertools\nimport os\nfrom contextlib import redirect_stdout\nfrom tqdm.notebook import tqdm"],"metadata":{"id":"251abdd1-1cd4-41f9-af70-23d22a1aa455","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e20eb56d-1d06-499e-bdfb-00ad81eb4e8b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["While we have used neural models so far, lets try a tree based model for this task. We use LightGBM library to train the main model. Lets set up few parameters for the lightgbm model, and specify some additional parameters:"],"metadata":{"id":"219f3784-220e-4889-ae88-09c80f556479","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41293702-13bb-4f77-a050-dc2c5d7afd6e"}}},{"cell_type":"code","source":["rand = 64\nlgb_params = {\n    \"objective\": \"binary\",\n    \"boosting\": \"gbdt\",\n    \"max_depth\": -1,\n    \"num_leaves\": 40,\n    \"subsample\": 0.8,\n    \"subsample_freq\": 1,\n    \"bagging_seed\": rand,\n    \"learning_rate\": 0.05,\n    \"feature_fraction\": 0.6,\n    \"min_data_in_leaf\": 100,\n    \"lambda_l1\": 0,\n    \"lambda_l2\": 0,\n    \"random_state\": rand,\n    \"metric\": \"auc\",#\"binary_logloss\",\n    \"verbose\": -1\n}\n\ntran_dtypes = {\"t_dat\":\"str\",\n               \"customer_id\":\"str\",\n               \"article_id\":\"int\",\n               \"product_code\":\"int\",\n               \"price\":\"float\",\n               \"sales_channel_id\":\"int\"}\nart_dtypes = {\"article_id\":\"int\",\n              \"product_code\":\"int\",\n              \"product_type_no\":\"int\",\n              \"graphical_appearance_no\":\"int\",\n              \"colour_group_code\":\"int\",\n              \"department_no\":\"int\",\n              \"index_code\":\"str\",\n              \"index_group_no\":\"int\",\n              \"section_no\":\"int\",\n              \"garment_group_no\":\"int\"}\ncust_dtypes = {\"customer_id\":\"str\"}\n\nobj = \"class\" # \"class\" or \"rank\"\nN = 15000\nn_iter = 2 # num of iteration\nidx_file = \"exp1\"\nn_round = 2000\nn_splits = 1\nnobuy = 20 # num of negative samples"],"metadata":{"id":"21e76b18-8d9e-4a1b-bf84-a929c8f16c6f","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3ba0a05a-5c18-4084-9531-e7ce87e6581c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["While we vary the user represnetations, we will keep the article representation fixed. The code below reads the article.csv file and extracts a number of features to represent articles."],"metadata":{"id":"3df9c2e0-af9e-406d-a9c6-c38a87347728","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f3811cac-7014-4be4-b91c-b1b406e74ca5"}}},{"cell_type":"code","source":["path = \"/dbfs/FileStore/anmol/co_rise/datasets/hmdata/\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3ae61cc-f952-4fd8-8b06-3f5b47a568fb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df = pd.read_csv(os.path.join(path, \"articles.csv\"))\n\n## Find categorical columns\nohe_columns = []\ntotal = 0\n\nfor col in df.columns:\n    if df[col].dtype == \"int64\" and len(df[col].unique()) <= 500:\n        ohe_columns.append(col)\n        total += len(df[col].unique())\n        \n## Do one hot encoding of the above categorical variables\nV = pd.get_dummies(df[ohe_columns], columns=ohe_columns).values\n\nprint(V.shape)\n\n## Get article features\ntfidf = TfidfVectorizer(min_df=3)\nV_desc = tfidf.fit_transform(df[\"detail_desc\"].fillna(\"nodesc\"))\n\n## Represent articles as vector of size 512\nEMB_SIZE = 32\nV = np.hstack([V.astype(\"float32\"), V_desc.todense()])\nsvd = TruncatedSVD(n_components=EMB_SIZE, random_state=0)\nsvd.fit(V)\nV = svd.transform(V)\n\nnp.save(\"articles.npy\", V)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fb93a7cd-a637-4960-9577-08449a57b55d","outputId":"cc893af0-cede-4576-fbc5-c001c97e7151","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0291ff55-3026-45e3-a2b6-358c91c80616"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">(105542, 622)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(105542, 622)\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df_art = pd.read_csv(os.path.join(path, \"articles.csv\"), dtype=art_dtypes)\ndf_art[\"index_code\"].unique()\n# le = LabelEncoder()\n# le.fit(df_art[\"index_code\"].unique())\n# df_art[\"index_code\"] = le.transform(df_art[\"index_code\"])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83ad55c1-d8b1-459e-8627-4de063632f00"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[19]: array([&#39;A&#39;, &#39;B&#39;, &#39;G&#39;, &#39;F&#39;, &#39;C&#39;, &#39;S&#39;, &#39;H&#39;, &#39;D&#39;, &#39;I&#39;, &#39;J&#39;], dtype=object)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[19]: array([&#39;A&#39;, &#39;B&#39;, &#39;G&#39;, &#39;F&#39;, &#39;C&#39;, &#39;S&#39;, &#39;H&#39;, &#39;D&#39;, &#39;I&#39;, &#39;J&#39;], dtype=object)</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def item_representation_1():\n    df_art = pd.read_csv(os.path.join(path, \"articles.csv\"), dtype=art_dtypes)\n    le = LabelEncoder()\n    le.fit(df_art[\"index_code\"].unique())\n    df_art[\"index_code\"] = le.transform(df_art[\"index_code\"])\n    \n    dict_vec = {}\n    vec_art = np.load(\"articles.npy\")\n    df_vec = pd.concat([df_art[\"article_id\"],pd.DataFrame(vec_art)],axis=1)\n    for i in range(len(vec_art)):\n        dict_vec[df_art[\"article_id\"][i]] = vec_art[i]\n    del vec_art,df_vec\n    \n    return df_art, dict_vec"],"metadata":{"id":"64a3715e-de70-49d4-b057-e0b674ca65ff","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94d991f0-14b9-4c90-b266-d508c1f6e624"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df_art, dict_vec = item_representation_1()\n\nprint(list(dict_vec.keys())[:10])\nprint(dict_vec[108775015].shape)\ndf_art.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"80bf75f2-bf25-4f10-9720-70e6bf89f451"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[108775015, 108775044, 108775051, 110065001, 110065002, 110065011, 111565001, 111565003, 111586001, 111593001]\n(512,)\nOut[21]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[108775015, 108775044, 108775051, 110065001, 110065002, 110065011, 111565001, 111565003, 111586001, 111593001]\n(512,)\nOut[21]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_id</th>\n      <th>product_code</th>\n      <th>prod_name</th>\n      <th>product_type_no</th>\n      <th>product_type_name</th>\n      <th>product_group_name</th>\n      <th>graphical_appearance_no</th>\n      <th>graphical_appearance_name</th>\n      <th>colour_group_code</th>\n      <th>colour_group_name</th>\n      <th>perceived_colour_value_id</th>\n      <th>perceived_colour_value_name</th>\n      <th>perceived_colour_master_id</th>\n      <th>perceived_colour_master_name</th>\n      <th>department_no</th>\n      <th>department_name</th>\n      <th>index_code</th>\n      <th>index_name</th>\n      <th>index_group_no</th>\n      <th>index_group_name</th>\n      <th>section_no</th>\n      <th>section_name</th>\n      <th>garment_group_no</th>\n      <th>garment_group_name</th>\n      <th>detail_desc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>108775015</td>\n      <td>108775</td>\n      <td>Strap top</td>\n      <td>253</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>9</td>\n      <td>Black</td>\n      <td>4</td>\n      <td>Dark</td>\n      <td>5</td>\n      <td>Black</td>\n      <td>1676</td>\n      <td>Jersey Basic</td>\n      <td>0</td>\n      <td>Ladieswear</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>16</td>\n      <td>Womens Everyday Basics</td>\n      <td>1002</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>108775044</td>\n      <td>108775</td>\n      <td>Strap top</td>\n      <td>253</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>10</td>\n      <td>White</td>\n      <td>3</td>\n      <td>Light</td>\n      <td>9</td>\n      <td>White</td>\n      <td>1676</td>\n      <td>Jersey Basic</td>\n      <td>0</td>\n      <td>Ladieswear</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>16</td>\n      <td>Womens Everyday Basics</td>\n      <td>1002</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>108775051</td>\n      <td>108775</td>\n      <td>Strap top (1)</td>\n      <td>253</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>1010017</td>\n      <td>Stripe</td>\n      <td>11</td>\n      <td>Off White</td>\n      <td>1</td>\n      <td>Dusty Light</td>\n      <td>9</td>\n      <td>White</td>\n      <td>1676</td>\n      <td>Jersey Basic</td>\n      <td>0</td>\n      <td>Ladieswear</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>16</td>\n      <td>Womens Everyday Basics</td>\n      <td>1002</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110065001</td>\n      <td>110065</td>\n      <td>OP T-shirt (Idro)</td>\n      <td>306</td>\n      <td>Bra</td>\n      <td>Underwear</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>9</td>\n      <td>Black</td>\n      <td>4</td>\n      <td>Dark</td>\n      <td>5</td>\n      <td>Black</td>\n      <td>1339</td>\n      <td>Clean Lingerie</td>\n      <td>1</td>\n      <td>Lingeries/Tights</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>61</td>\n      <td>Womens Lingerie</td>\n      <td>1017</td>\n      <td>Under-, Nightwear</td>\n      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>110065002</td>\n      <td>110065</td>\n      <td>OP T-shirt (Idro)</td>\n      <td>306</td>\n      <td>Bra</td>\n      <td>Underwear</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>10</td>\n      <td>White</td>\n      <td>3</td>\n      <td>Light</td>\n      <td>9</td>\n      <td>White</td>\n      <td>1339</td>\n      <td>Clean Lingerie</td>\n      <td>1</td>\n      <td>Lingeries/Tights</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>61</td>\n      <td>Womens Lingerie</td>\n      <td>1017</td>\n      <td>Under-, Nightwear</td>\n      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_id</th>\n      <th>product_code</th>\n      <th>prod_name</th>\n      <th>product_type_no</th>\n      <th>product_type_name</th>\n      <th>product_group_name</th>\n      <th>graphical_appearance_no</th>\n      <th>graphical_appearance_name</th>\n      <th>colour_group_code</th>\n      <th>colour_group_name</th>\n      <th>perceived_colour_value_id</th>\n      <th>perceived_colour_value_name</th>\n      <th>perceived_colour_master_id</th>\n      <th>perceived_colour_master_name</th>\n      <th>department_no</th>\n      <th>department_name</th>\n      <th>index_code</th>\n      <th>index_name</th>\n      <th>index_group_no</th>\n      <th>index_group_name</th>\n      <th>section_no</th>\n      <th>section_name</th>\n      <th>garment_group_no</th>\n      <th>garment_group_name</th>\n      <th>detail_desc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>108775015</td>\n      <td>108775</td>\n      <td>Strap top</td>\n      <td>253</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>9</td>\n      <td>Black</td>\n      <td>4</td>\n      <td>Dark</td>\n      <td>5</td>\n      <td>Black</td>\n      <td>1676</td>\n      <td>Jersey Basic</td>\n      <td>0</td>\n      <td>Ladieswear</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>16</td>\n      <td>Womens Everyday Basics</td>\n      <td>1002</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>108775044</td>\n      <td>108775</td>\n      <td>Strap top</td>\n      <td>253</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>10</td>\n      <td>White</td>\n      <td>3</td>\n      <td>Light</td>\n      <td>9</td>\n      <td>White</td>\n      <td>1676</td>\n      <td>Jersey Basic</td>\n      <td>0</td>\n      <td>Ladieswear</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>16</td>\n      <td>Womens Everyday Basics</td>\n      <td>1002</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>108775051</td>\n      <td>108775</td>\n      <td>Strap top (1)</td>\n      <td>253</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>1010017</td>\n      <td>Stripe</td>\n      <td>11</td>\n      <td>Off White</td>\n      <td>1</td>\n      <td>Dusty Light</td>\n      <td>9</td>\n      <td>White</td>\n      <td>1676</td>\n      <td>Jersey Basic</td>\n      <td>0</td>\n      <td>Ladieswear</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>16</td>\n      <td>Womens Everyday Basics</td>\n      <td>1002</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110065001</td>\n      <td>110065</td>\n      <td>OP T-shirt (Idro)</td>\n      <td>306</td>\n      <td>Bra</td>\n      <td>Underwear</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>9</td>\n      <td>Black</td>\n      <td>4</td>\n      <td>Dark</td>\n      <td>5</td>\n      <td>Black</td>\n      <td>1339</td>\n      <td>Clean Lingerie</td>\n      <td>1</td>\n      <td>Lingeries/Tights</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>61</td>\n      <td>Womens Lingerie</td>\n      <td>1017</td>\n      <td>Under-, Nightwear</td>\n      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>110065002</td>\n      <td>110065</td>\n      <td>OP T-shirt (Idro)</td>\n      <td>306</td>\n      <td>Bra</td>\n      <td>Underwear</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>10</td>\n      <td>White</td>\n      <td>3</td>\n      <td>Light</td>\n      <td>9</td>\n      <td>White</td>\n      <td>1339</td>\n      <td>Clean Lingerie</td>\n      <td>1</td>\n      <td>Lingeries/Tights</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>61</td>\n      <td>Womens Lingerie</td>\n      <td>1017</td>\n      <td>Under-, Nightwear</td>\n      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Taken together, the two cells above give us all the features we want to represent articles."],"metadata":{"id":"7cbe5f64-354c-451e-a9e0-eb114440f8f0","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"923246fc-1d1d-427c-9b3d-0bd741c027ee"}}},{"cell_type":"markdown","source":["Now lets define some functions to extract user representations. The different functions will contain different ways of representing users.\n\nWe bootstrap by providing a simple set of features to represent users in user_representation_1(). This function returns the dataframe of user features."],"metadata":{"id":"f0c3082e-1da7-466f-8b9f-c777c8ef63cd","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e6d6b653-02ec-4b33-b5ec-30edabb822b9"}}},{"cell_type":"code","source":["def user_representation_1():\n    df_cust = pd.read_csv(os.path.join(path, \"customers.csv\"), dtype=cust_dtypes)\n    df_cust[\"age\"] = df_cust[\"age\"].fillna(df_cust[\"age\"].mean())\n    df_cust[[\"FN\",\"Active\"]] = df_cust[[\"FN\",\"Active\"]].fillna(0)\n    df_cust[\"club_member_status\"] = df_cust[\"club_member_status\"].apply(lambda x:1 if x == \"ACTIVE\" else 0)\n    df_cust[\"fashion_news_frequency\"] = df_cust[\"fashion_news_frequency\"].apply(lambda x:0 if x == \"NONE\" else 1)\n    df_cust = df_cust.drop([\"postal_code\"], axis=1)\n    return df_cust"],"metadata":{"id":"5de63a95-ef6c-4796-8e59-0cb33b9b948e","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57a7a7ee-58a6-412c-8916-d48fcb278b07"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df_cust = user_representation_1()\ndf_cust.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"342e99a9-f6c6-4fa8-8073-781a82aa2f57"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[23]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[23]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>FN</th>\n      <th>Active</th>\n      <th>club_member_status</th>\n      <th>fashion_news_frequency</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>49.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>54.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>52.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>FN</th>\n      <th>Active</th>\n      <th>club_member_status</th>\n      <th>fashion_news_frequency</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>49.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>54.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>52.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def user_representation_3():\n    \"\"\"\n    OPTIONAL -- compute user representations as the output\n    of the doc2vec model.\n    https://cs.stanford.edu/~quocle/paragraph_vector.pdf\n    Doc2vec model is an embedding learning method\n    that enables us to learn representations of a document.\n    We treat each user as a document, and the set of articles\n    the user has purchased as the set of words in the document.\n    \"\"\"\n    return None"],"metadata":{"id":"65dbcef5-701a-4999-b696-3d871ccb485d","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6136747-3aa0-478c-b9f8-6e5876571308"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["As part of the goal for part B of this week's project, please use the above two functions to implement the two user representation techniques mentioned in the project jumpstart.\n\nYou can run the rest of the notebook for now, and come back to these functions, implement them and re-run some of the code below and use user_representation_2() (and optionally user_representation_3()) to get the appropriate user features to use to train the model for the downstream task.\n\nLets write a function that would read the transactions data and return the dataframes for the transactions within the dates we want to consider, along with the dataframes for articles features: df_art and dict_vec."],"metadata":{"id":"d39b7430-bf43-4f16-b7a8-a6edbd078e1d","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"461b1d7f-a281-4ba5-8646-73f88106c44a"}}},{"cell_type":"code","source":["def read_data(day_oldest):\n    df_trans = pd.read_csv(os.path.join(path, \"transactions_train.csv\"), dtype=tran_dtypes)\n    df_trans[\"t_dat\"] = pd.to_datetime(df_trans[\"t_dat\"],format=\"%Y-%m-%d\")\n\n    df_trans = df_trans.query(f\"t_dat >= '{day_oldest}'\").copy()\n    df_trans = df_trans.drop_duplicates([\"customer_id\",\"article_id\",\"t_dat\"])\n    df_art,dict_vec = item_representation_1()\n    df_trans = df_trans.merge(df_art[[\"article_id\",\"product_code\",\"product_type_no\",\"graphical_appearance_no\",\"colour_group_code\",\"department_no\",\"index_code\",\"index_group_no\",\"section_no\",\"garment_group_no\"]],how=\"left\",on=\"article_id\")\n\n    return df_trans, df_art, dict_vec"],"metadata":{"id":"55c3e4dd-ce84-4199-9215-06490305db3c","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69f060c4-0f9a-472a-a78b-64d60d42c99d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df_trans, df_art, dict_vec = read_data(datetime.datetime(2018,9,23))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6362eed3-9739-43ab-863a-ee88725c2db5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df_trans[\"t_dat\"].apply(lambda x: x.year).value_counts()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31ba1e87-3da1-4886-a562-d885d86bc7f0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[27]: 2019    14688180\n2020     9896663\n2018     3887956\nName: t_dat, dtype: int64</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[27]: 2019    14688180\n2020     9896663\n2018     3887956\nName: t_dat, dtype: int64</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# item_embeddings = pd.DataFrame(dict_vec).transpose()\n\n# day_oldest = datetime.datetime(2020,1,1)\n\n# user_embeddings = df_trans\\\n# .query(f\"t_dat >= '{day_oldest}'\")\\\n# [[\"customer_id\", \"article_id\"]]\\\n# .merge(item_embeddings\\\n#        .reset_index()\\\n#        .rename(columns={\"index\":\"article_id\"})\\\n#        , how=\"inner\", on=\"article_id\")\\\n# [[\"customer_id\"]+list(range(EMB_SIZE))]\\\n# .groupby(\"customer_id\")\\\n# .agg(np.mean)\n\n# user_embeddings.head(100).join(user_embeddings[\"customer_id\"].unique(), on=\"customer_id\", how=\"inner\")\n# item_embeddings = pd.DataFrame(dict_vec).transpose()\n# cust_txns = df_trans[[\"customer_id\", \"article_id\"]].groupby(\"customer_id\").get_group(df_trans[\"customer_id\"][0])\n\n# def get_a_vec_mean(cust_txns):\n#   return item_embeddings.loc[cust_txns[\"article_id\"].unique()].apply(np.mean, axis=0)\n#   # return np.sum([dict_vec[a] for a in cust_txns[\"article_id\"]], axis=0)\n\n# item_embeddings = pd.DataFrame(dict_vec).transpose()\n\n# user_embeddings = df_trans\\\n# [[\"customer_id\", \"article_id\"]]\\\n# .groupby(\"customer_id\")\\\n# .apply(lambda cust_txns: get_a_vec_mean(cust_txns))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57cfa7fd-af9e-46b4-b571-9cba01d67f4f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now we have all the ingredients we need -- we have a basic version of user representations and we have the article representations, and transactions data on which we can train our downstream task.\n\nThe downstream task we consider is the task of predicting whether or not a user will purchase an article. This is the same task that we have been dealing with in the past 2 weeks.\n\nLets define a train() function that will consider the start and end dates and split data based on these, generate the training data, do random negative sampling and train the model."],"metadata":{"id":"4128aa41-0a7c-405c-a2c2-02a3e19678f2","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ce1e79dc-7d08-416e-8604-92a42a7df14d"}}},{"cell_type":"code","source":["def train():\n    #### Transaction start date say it is from 2019/9/23 and say we take 1 week data\n    day_start = datetime.datetime(2019,9,23) - datetime.timedelta(days=6)\n    #### Transaction end date\n    day_end = datetime.datetime(2019,9,23) - datetime.timedelta(days=0)\n    \n    ######## Splitting data based on date ###########################\n    ####### Train date ###########################################\n    ## Let's consider the training data for 1 year\n    day_start_hist = day_start - datetime.timedelta(days=366)\n    day_end_hist = day_start - datetime.timedelta(days=1)\n    \n    df_trans, df_art, dict_vec = read_data(day_oldest = datetime.datetime(2018,9,23))\n\n    df_cust = user_representation_1()\n    \n    query_date = f\"((t_dat >= '{day_start}') and (t_dat <= '{day_end}'))\"\n    top_art_all = df_trans.query(query_date ).groupby(\"article_id\")[\"t_dat\"].count().sort_values(ascending = False).index[:N].tolist()\n\n    ############### Create training data #################################################################################\n    \n    \n    list_df_buy = []\n    list_cust =[]\n    \n    # make positive samples\n    list_df_buy = df_trans.query(f\"(t_dat >= '{day_start}') and (t_dat <= '{day_end}') and (article_id in @top_art_all)\").drop_duplicates([\"customer_id\",\"article_id\"])[[\"customer_id\",\"article_id\"]].copy()\n    list_df_buy[\"target\"] = 1\n    list_cust = list_df_buy[\"customer_id\"].unique().tolist()\n        \n        \n    # make negative samples (random selection)\n    \n    list_df_nobuy = pd.concat([pd.DataFrame({\"customer_id\":x,\"article_id\":random.sample(top_art_all,nobuy)}) for x in list_cust])\n    list_df_nobuy[\"target\"] = 0\n    list_train = pd.concat([list_df_buy,list_df_nobuy]).drop_duplicates([\"customer_id\",\"article_id\"])\n    del list_df_nobuy\n\n    # add feature\n    df_train = pd.DataFrame()\n    \n    ########## Merging item features with the transactions data ###################################################\n    list_train = list_train.merge(df_art[[\"article_id\",\"product_code\",\"product_type_no\",\"graphical_appearance_no\",\"colour_group_code\",\"department_no\",\"index_code\",\"index_group_no\",\"section_no\",\"garment_group_no\"]],how=\"left\",on=\"article_id\")\n    \n    ######### Merging customer data with the above data ######################################\n    list_train = list_train.merge(df_cust, how=\"left\", on=\"customer_id\")\n    df_train = df_train.append(list_train)\n    del list_train\n    gc.collect()\n    \n    \n    # now that we have all the data in place, lets train the lgbm model\n\n    # train lgbm\n    X_train = df_train.drop([\"customer_id\",\"product_code\",\"product_type_no\",\"department_no\",\"target\"],axis=1)\n    y_train = df_train[\"target\"]\n    del df_train\n    \n    X_tr, X_va, y_tr, y_va = train_test_split(X_train,y_train,stratify = y_train)\n    d_tr = lgb.Dataset(X_tr, label=y_tr,  free_raw_data=False)\n    d_va = lgb.Dataset(X_va, label=y_va,  free_raw_data=False)\n    lgbm_model = lgb.train(lgb_params, train_set=d_tr, num_boost_round=n_round, valid_sets=[d_tr,d_va], verbose_eval=500, early_stopping_rounds=100)\n    \n    # save model\n    pd.to_pickle(lgbm_model,\"lgbm_model.pkl\")\n    del X_train, y_train, X_tr, X_va, y_tr, y_va, d_tr, d_va\n    gc.collect()\n    del df_trans, df_art, df_cust\n    gc.collect()\n    return 0"],"metadata":{"id":"5e0c7a4f-8e4d-42f7-b379-1ebc870375d9","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dff3cd71-45dc-43c1-904f-5419bb17a41f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"afb1b72d-7f50-4dc8-a44c-95dcf9c537d2","outputId":"842ea858-0607-4114-e485-4c36be7d2041","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b9d291c-0bb1-44dc-b51b-25fa7e1d3613"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/python/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: &#39;early_stopping_rounds&#39; argument is deprecated and will be removed in a future release of LightGBM. Pass &#39;early_stopping()&#39; callback via &#39;callbacks&#39; argument instead.\n  _log_warning(&#34;&#39;early_stopping_rounds&#39; argument is deprecated and will be removed in a future release of LightGBM. &#34;\n/databricks/python/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: &#39;verbose_eval&#39; argument is deprecated and will be removed in a future release of LightGBM. Pass &#39;log_evaluation()&#39; callback via &#39;callbacks&#39; argument instead.\n  _log_warning(&#34;&#39;verbose_eval&#39; argument is deprecated and will be removed in a future release of LightGBM. &#34;\nTraining until validation scores don&#39;t improve for 100 rounds\n[500]\ttraining&#39;s auc: 0.809788\tvalid_1&#39;s auc: 0.805089\n[1000]\ttraining&#39;s auc: 0.824247\tvalid_1&#39;s auc: 0.816166\n[1500]\ttraining&#39;s auc: 0.832856\tvalid_1&#39;s auc: 0.821529\n[2000]\ttraining&#39;s auc: 0.83924\tvalid_1&#39;s auc: 0.824926\nDid not meet early stopping. Best iteration is:\n[2000]\ttraining&#39;s auc: 0.83924\tvalid_1&#39;s auc: 0.824926\nOut[65]: 0</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: &#39;early_stopping_rounds&#39; argument is deprecated and will be removed in a future release of LightGBM. Pass &#39;early_stopping()&#39; callback via &#39;callbacks&#39; argument instead.\n  _log_warning(&#34;&#39;early_stopping_rounds&#39; argument is deprecated and will be removed in a future release of LightGBM. &#34;\n/databricks/python/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: &#39;verbose_eval&#39; argument is deprecated and will be removed in a future release of LightGBM. Pass &#39;log_evaluation()&#39; callback via &#39;callbacks&#39; argument instead.\n  _log_warning(&#34;&#39;verbose_eval&#39; argument is deprecated and will be removed in a future release of LightGBM. &#34;\nTraining until validation scores don&#39;t improve for 100 rounds\n[500]\ttraining&#39;s auc: 0.809788\tvalid_1&#39;s auc: 0.805089\n[1000]\ttraining&#39;s auc: 0.824247\tvalid_1&#39;s auc: 0.816166\n[1500]\ttraining&#39;s auc: 0.832856\tvalid_1&#39;s auc: 0.821529\n[2000]\ttraining&#39;s auc: 0.83924\tvalid_1&#39;s auc: 0.824926\nDid not meet early stopping. Best iteration is:\n[2000]\ttraining&#39;s auc: 0.83924\tvalid_1&#39;s auc: 0.824926\nOut[65]: 0</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We have now trained a light gbm model using user_representation_1() function as the user representation technique. The key goals for part B of this week's project are to implement user_representation_2(), where we represent the user as the average of embeddings of their recently purchased articles."],"metadata":{"id":"2a4b63a5-56ee-4bd2-b7b8-2aebb5299b31","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d77bbfa2-c971-4f5a-988a-4259d81b3b0f"}}},{"cell_type":"markdown","source":["Once you have implemented the function, please note to change the line:\n\ndf_cust = user_representation_1()\n\nto the appropriate function name and run re-train the model. Please report the performance numbers with each of the two user representations.\n\nThis should complete the week 3 project!"],"metadata":{"id":"4940f48d-08e5-4130-be2c-d15622012620","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4390abef-7e8d-40a4-baff-2d8fb9f36845"}}},{"cell_type":"code","source":["def get_mean_a_vec(cust_txns):\n  return item_embeddings.loc[cust_txns].apply(np.mean, axis=0)\n  # return item_embeddings.loc[cust_txns.unique()].apply(np.mean, axis=0)\n  # return np.sum([dict_vec[a] for a in cust_txns], axis=0)\n  \ndef user_representation_2(df_trans, dict_vec):\n# def user_representation_2(df_trans):\n    \"\"\"\n    TODO -- compute user representations as the average\n    of the embeddings of the recently purchased articles\n    return user representation\n    \n    # Leakage - a customer bought something the next day which was in previous day\n\n    Hint: You may find pd.DataFrame(item_representation_1()[1]).transpose() useful\n    \"\"\"\n    \n    item_embeddings = pd.DataFrame(dict_vec).transpose()\n    max_date = df_trans[\"t_dat\"].max()\n    user_embeddings = df_trans\\\n    .query(f\"t_dat >= '{datetime.datetime(2020, 1, 1)}'\")\\\n    .query(f\"t_dat < '{datetime.datetime(2020, 1, 15)}'\")\\\n    [[\"customer_id\", \"article_id\"]]\\\n    .groupby(\"customer_id\")\\\n    [\"article_id\"]\\\n    .apply(list)\\\n    .apply(lambda cust_txns: get_mean_a_vec(cust_txns[:5]))\n    # .apply(lambda cust_txns: get_mean_a_vec(cust_txns, dict_vec=dict_vec))\n    \n    return user_embeddings"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08a5a89d-d80f-40b7-b39a-8f663cee254b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def train2():\n    #### Transaction start date say it is from 2019/9/23 and say we take 1 week data\n    day_start = datetime.datetime(2019,9,23) - datetime.timedelta(days=6)\n    #### Transaction end date\n    day_end = datetime.datetime(2019,9,23) - datetime.timedelta(days=0)\n    \n    ######## Splitting data based on date ###########################\n    ####### Train date ###########################################\n    ## Let's consider the training data for 1 year\n    day_start_hist = day_start - datetime.timedelta(days=366)\n    day_end_hist = day_start - datetime.timedelta(days=1)\n    \n    df_trans, df_art, dict_vec = read_data(day_oldest = datetime.datetime(2018,9,23))\n\n    # df_cust = user_representation_1()\n    df_cust = user_representation_2(df_trans, dict_vec)\n\n    query_date = f\"((t_dat >= '{day_start}') and (t_dat <= '{day_end}'))\"\n    top_art_all = df_trans.query(query_date ).groupby(\"article_id\")[\"t_dat\"].count().sort_values(ascending = False).index[:N].tolist()\n\n    ############### Create training data #################################################################################\n    \n    \n    list_df_buy = []\n    list_cust =[]\n    \n    # make positive samples\n    list_df_buy = df_trans.query(f\"(t_dat >= '{day_start}') and (t_dat <= '{day_end}') and (article_id in @top_art_all)\").drop_duplicates([\"customer_id\",\"article_id\"])[[\"customer_id\",\"article_id\"]].copy()\n    list_df_buy[\"target\"] = 1\n    list_cust = list_df_buy[\"customer_id\"].unique().tolist()\n        \n        \n    # make negative samples (random selection)\n    \n    list_df_nobuy = pd.concat([pd.DataFrame({\"customer_id\":x,\"article_id\":random.sample(top_art_all,nobuy)}) for x in list_cust])\n    list_df_nobuy[\"target\"] = 0\n    list_train = pd.concat([list_df_buy,list_df_nobuy]).drop_duplicates([\"customer_id\",\"article_id\"])\n    del list_df_nobuy\n\n    # add feature\n    df_train = pd.DataFrame()\n    \n    ########## Merging item features with the transactions data ###################################################\n    list_train = list_train.merge(df_art[[\"article_id\",\"product_code\",\"product_type_no\",\"graphical_appearance_no\",\"colour_group_code\",\"department_no\",\"index_code\",\"index_group_no\",\"section_no\",\"garment_group_no\"]],how=\"left\",on=\"article_id\")\n    \n    ######### Merging customer data with the above data ######################################\n    list_train = list_train.merge(df_cust, how=\"left\", on=\"customer_id\")\n    df_train = df_train.append(list_train)\n    del list_train\n    gc.collect()\n    \n    \n    # now that we have all the data in place, lets train the lgbm model\n\n    # train lgbm\n    X_train = df_train.drop([\"customer_id\",\"product_code\",\"product_type_no\",\"department_no\",\"target\"],axis=1)\n    y_train = df_train[\"target\"]\n    del df_train\n    \n    X_tr, X_va, y_tr, y_va = train_test_split(X_train,y_train,stratify = y_train)\n    d_tr = lgb.Dataset(X_tr, label=y_tr,  free_raw_data=False)\n    d_va = lgb.Dataset(X_va, label=y_va,  free_raw_data=False)\n    lgbm_model = lgb.train(lgb_params, train_set=d_tr, num_boost_round=n_round, valid_sets=[d_tr,d_va], verbose_eval=500, early_stopping_rounds=100)\n    \n    # save model\n    pd.to_pickle(lgbm_model,\"lgbm_model.pkl\")\n    del X_train, y_train, X_tr, X_va, y_tr, y_va, d_tr, d_va\n    gc.collect()\n    del df_trans, df_art, df_cust\n    gc.collect()\n    return 0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa9420ac-c506-4bff-b0a3-e89c13869cab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["train2()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b77e0dbf-aeb0-479a-b6eb-f4f665e42acc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Optional task 1: training a Doc2Vec model\n\nIf you want an extra challenge, you can try implementing Doc2vec representations in user_representation_3(). The Doc2vec model is an embedding learning method\n    that enables us to learn representations of a document.\n    We treat each user as a document, and the set of articles\n    the user has purchased as the set of words in the document."],"metadata":{"id":"ydLW7dPiuw-E","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3aca4d28-0a73-4e34-85e2-684ea666cdf5"}}},{"cell_type":"markdown","source":["### Optional task 2: training a sequential LSTM model\n\nAnother optional task here would be to implement user_representation_4() where user representations are learnt by a sequential LSTM model. The LSTM model will need to be trained on a task -- the task itself could be the downstream task of predicting whether or not a user would purchase a given article given a sequence of previous articles. The final hidden layer of the lstm model can be used as the user representation."],"metadata":{"id":"ce141145-f5af-4f2d-9d94-f4bb50e6208f","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c1acf55-3b16-4523-adfc-f79f0ebca58f"}}},{"cell_type":"code","source":[""],"metadata":{"id":"88eb3b58-062c-4c96-b3f0-2db4407ce1b3","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5543f189-f5fd-434d-9378-a9b283b04095"}},"outputs":[],"execution_count":0}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.12","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"application/vnd.databricks.v1+notebook":{"notebookName":"week3_ann_user_representations","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3041134188635428},"environment":{"kernel":"python3","name":"tf2-gpu.2-6.m89","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m89"},"gpuClass":"standard","colab":{"machine_shape":"hm","name":"week3-ann-user-representations.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
